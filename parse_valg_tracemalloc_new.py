import os, sys
import math
import matplotlib.font_manager as fm
import matplotlib.pyplot as plt
from matplotlib.ticker import FormatStrFormatter
import numpy as np

params = {'figure.figsize'  : [10, 7.2],
		  # 'font.family': 'MankSans-Medium',
		  'pdf.fonttype' : 42,
          'ps.fonttype' : 42,
		  'grid.color': '#aaaaaa',
		  'grid.linestyle': '--',
		  'grid.linewidth': 1.5,
		  'figure.autolayout': True,
		  } 

fontsz = 23
plt.rcParams.update(params)

SMALL_PG_SZ = 4096

# TODO1: Mar21: NEED to add the addr of malloc as well
# Will help decide b/w using new mem or freed mem for the malloc (based on relative offset from first ptr)
# Done2: in valgrind logs, free can be called multiple times!!! Check for duplicates
# Done3: in valgrind logs, round up malloc_sz to 16bytes.
# TODO4: first line: put first malloc addr - 64 (i.e. absolute offset)

def write_workload_to_file(imalloc_list, ifreed_allocs_dict, fname):
	s = ""
	for mi in range(len(imalloc_list)):
		s += "malloc %i %i \n"%(mi, imalloc_list[mi][0])
	for free_index in sorted(list(ifreed_allocs_dict.keys())):
		for free_malloc_id in sorted(ifreed_allocs_dict[free_index]):
			s += "free %i \n"%(free_malloc_id)
	with open(fname, 'w') as f:
		f.write(s)

# event_list: each event is either (sz,addr,mid) or (free_addr,free,mid)
def write_valg_workload_to_file(event_list, fname):
	s = ""
	if len(event_list) > 0 and "free" not in event_list[0][1]:
		base_addr = (int(event_list[0][1], base=16)//SMALL_PG_SZ)*SMALL_PG_SZ # new: pg boundary based # old: - 64
		# s += "%i\n"%(base_addr) # base addr to get offset of all mallocs:
		for ei in range(len(event_list)):
			if "free" not in event_list[ei][1]:
				round_sz = 16*(math.ceil(event_list[ei][0]/16))
				s += "malloc %i %i %i\n"%( round_sz, int(event_list[ei][1], base=16) - base_addr, event_list[ei][2] )
			else:
				s += "free %i %i\n"%( int(event_list[ei][0], base=16) - base_addr, event_list[ei][2])
		with open(fname, 'w') as f:
			f.write(s)
	else:
		print("WEIRD event_list: len: %i, 1st event: %s"%( len(event_list), str(event_list[0]) ))


def plot_malloc_stats(imalloc_list, ifname):
	orig_malloc_sz_sum = sum([x[0] for x in imalloc_list])
	malloc_sz_list = [ int(16*math.ceil(x[0]/16)) for x in imalloc_list]
	print("[Total #mallocs: %i] Min: %i, median: %i, avg: %i, max: %i [Original malloc sz sum: %i]"%(len(malloc_sz_list), min(malloc_sz_list), np.percentile(malloc_sz_list, 50), sum(malloc_sz_list)/len(malloc_sz_list), max(malloc_sz_list), orig_malloc_sz_sum) )
	print("Counts: 8192: %i , 16: %i"%(malloc_sz_list.count(8192), malloc_sz_list.count(16)))
	# plt.yscale("log")
	plt.hist(malloc_sz_list, [16,32,48,64,80,96,160,512,2048,8192]) # 524288,33554980
	plt.xlabel("Allocation size (bytes)", fontsize=fontsz)
	plt.ylabel("#Allocations", fontsize=fontsz)
	plt.xticks(fontsize=fontsz)
	plt.yticks(fontsize=fontsz)
	plt.locator_params(axis='y')
	plt.savefig(ifname)
	plt.show()

def plot_active_malloc_stats(imalloc_avg_list, ifname):
	print("[Active Malloc Avg List] Count: %i, min: %i, median: %i, avg: %i, max: %i "%( len(imalloc_avg_list), min(imalloc_avg_list), np.percentile(imalloc_avg_list, 50), np.mean(imalloc_avg_list), max(imalloc_avg_list) ) )
	# plot_arr([], )

def plot_arr(x_arr, y_arr, xl, yl, titl, ifname):
	# index = np.arange(len(arr)) + 0.3
	# bar_width = 0.4
	# plt.bar(index, )
	plt.plot(x_arr, y_arr, 'bo-')
	plt.xlabel(xl, fontsize=fontsz)
	plt.ylabel(yl, fontsize=fontsz)
	plt.xticks(fontsize=fontsz)
	plt.yticks(fontsize=fontsz)
	plt.savefig(ifname)
	plt.show()

# ONLY account for the apr_palloc, pool_alloc calls, i.e. ignore  the APR CMA metadata (e.g. node/pool/allocator)
# free: find the free with largest addr <= addr for each malloc_addr [for apr_palloc, pool_alloc]
def read_apache_logs_V1(log_fname, out_fname, hist_fname):
	malloc_list = []  # stores tuples of (malloc sz, ptr)
	freed_dict = {} # stores ptr->free'd index.
	with open(log_fname) as f:
		for fl in f.readlines():
			try:
				if "APR_PALLOC: Actual alloc size:" in fl:
					addr = int(fl.split(' ')[8],base=16)
					if addr < 79499320:
						print("###### WEIRD malloc addr: ", fl)
					else:
						malloc_list.append( ( int(fl.split(' ')[4] ), addr ) )
				elif "POOL_ALLOC: CALLED malloc for mem" in fl:
					addr = int(fl.split(' ')[8],base=16)
					if addr < 79499320:
						print("###### WEIRD malloc addr: ", fl)
					else:
						malloc_list.append( (int(fl.split(' ')[6]), int(fl.split(' ')[8],base=16)) )
				elif "Calling free on" in fl:
					freed_ptr = int( fl.split(' ')[4] , base=16)
					freed_dict[freed_ptr] = len(freed_dict)
			except:
				print("###### ERROR in Line ", fl)
				# raise
	freed_allocs_dict = {} # stores free'd index->list of malloc' items that it frees
	freed_addr_list = sorted(list(freed_dict.keys()))
	for i in range(len(malloc_list)):
		malloc_item = malloc_list[i]

		# find the free that frees this malloc_item:
		try:
			freed_addr = max( [fa for fa in freed_addr_list if (fa <= malloc_item[1])] )
			freed_index = freed_dict[freed_addr]

			# add this to freed_allocs_dict:
			if freed_index not in freed_allocs_dict:
				freed_allocs_dict[freed_index] = []
			freed_allocs_dict[freed_index].append(i)
		except:
			print("ERROR for malloc item", malloc_item, "index: ", i, "freed_addr_list: ", freed_addr_list)
			raise
	plot_malloc_stats(malloc_list, hist_fname)
	write_workload_to_file(malloc_list, freed_allocs_dict, out_fname)


# Account for node [40bytes in allocator_alloc]/pool [sizeof_pool in ?]/allocator [?] metadata
# Along with apr_palloc, pool_alloc calls
# free: find the free with largest addr <= addr for each malloc_addr [for apr_palloc, pool_alloc]
def read_apache_logs_V2(fname, out_fname, hist_fname):
	malloc_list = []
	freed_dict = {}
	counts = {"APR_PALLOC: Actual alloc size": 0, "POOL_ALLOC: CALLED malloc for mem": 0, "pool metadata space": 0, "node first_avail is": 0, "make new_allocator": 0}
	with open(fname) as f:
		for fl in f.readlines():
			try:
				if "APR_PALLOC: Actual alloc size:" in fl:
					addr = int(fl.split(' ')[8],base=16)
					if addr < 79499320:
						print("###### WEIRD malloc addr: ", fl)
					else:
						malloc_list.append( ( int(fl.split(' ')[4] ), addr ) )
						counts["APR_PALLOC: Actual alloc size"] += 1
				elif "POOL_ALLOC: CALLED malloc for mem" in fl:
					addr = int(fl.split(' ')[8],base=16)
					if addr < 79499320:
						print("###### WEIRD malloc addr: ", fl)
					else:
						malloc_list.append( (int(fl.split(' ')[6]), int(fl.split(' ')[8],base=16)) )
						counts["POOL_ALLOC: CALLED malloc for mem"] += 1
				# apr metadata:
				elif "pool metadata space" in fl:
					malloc_list.append( ( int(fl.split(' ')[9]), 0 ) )
					counts["pool metadata space"] += 1
				elif "node first_avail is" in fl:
					malloc_list.append( (int(fl.split(' ')[4]), 0) )
					counts["node first_avail is"] += 1
				elif "make new_allocator" in fl:
					malloc_list.append( (int(fl.split(' ')[8]), 0) )
					counts["make new_allocator"] += 1
				elif "Calling free on" in fl:
					freed_ptr = int( fl.split(' ')[4] , base=16)
					freed_dict[freed_ptr] = len(freed_dict)
			except:
				print("###### ERROR in Line ", fl)
	print(counts)
	plot_malloc_stats(malloc_list, hist_fname)
	#Todo: convert malloc list, free list to workload. Main Issue: Order

def process_new_active_alloc(m_active_dict, msz, maddr):
	m_active_dict[maddr] = msz
	return m_active_dict

def process_free_active_alloc(m_active_dict, maddr):
	if maddr in m_active_dict:
		del m_active_dict[maddr]
	return m_active_dict

def process_new_alloc(mdict, mlist, elist, msz, maddr):
	mid = len(elist)
	if (maddr in mdict):
		if mdict[maddr][2] == 0:
			print("DUPLICATE!!!!! maddr: ", maddr, " already in dict: ", mdict[maddr])
			raise Exception
		# else:
			# print("RE-USING FREED MEMORY maddr: ", maddr, " alreay in dict: ", mdict[maddr])
	mdict[ maddr ] = ( msz , mid, 0) # size, id, if its has been freed yet
	mlist.append( (msz, maddr) )
	elist.append( (msz, maddr, mid) )
	return (mdict, mlist, elist)

def process_free_alloc(mdict, elist, f_weird_list, free_addr):
	if free_addr in mdict:
		m_eid = mdict[free_addr][1]
		mdict[free_addr] = (mdict[free_addr][0], m_eid, 1)
		elist.append( ( free_addr, "free", m_eid) )
	else:
		f_weird_list.append(free_addr)
	return (mdict, elist, f_weird_list)

def debug(fname):
	with open(fname) as f:
		all19351 = []
		valid19351 = []
		invalid19351 = []
		parsed19351 = []
		mrc19351 = []
		nonmrc19351 = []
		ditched19351 = []
		for fl in f.readlines():
			if "19351" in fl:
				all19351.append(fl)
				valid_lines = ["alloc(", "free(", "_Znwm", "_ZdlPv", "memalign(", "_Znam", "ZdaPv("]
				is_valid_fl = sum([ (x in fl) for x in valid_lines ])
				if is_valid_fl > 0:
					valid19351.append(fl)
					if " malloc(" in fl or " calloc(" in fl or " realloc(" in fl:
						mrc19351.append(fl)
					elif "free(" not in fl:
						nonmrc19351.append(fl)

					if " malloc(" in fl or " calloc(" in fl or " realloc(" in fl or "memalign" in fl or "free(" in fl:
						parsed19351.append(fl)					
					else:
						ditched19351.append(fl)
				else:
					invalid19351.append(fl)
		print("LENs: all: %i, valid: %i, invalid: %i, parsed: %i, ditched: %i"%(len(all19351), len(valid19351), len(invalid19351), len(parsed19351), len(ditched19351)))
		print(invalid19351)
		print("mrc: %i, nonmrc: %i "%(len(mrc19351), len(nonmrc19351)))

def handle_missing_allocs(mdict, mlist, elist, fl, max_addr_alloc):
	# in a separate page, addr beyond total_mem_usage 
	num_allocs = int( fl.split(' ')[6].replace(',', '') )
	num_alloc_bytes = int( fl.split(' ')[-3].replace(',','') )

	if (num_allocs > len(mlist)):
	# #allocs & Sizes:
		# all but 1 are of size 16bytes, 
		start_addr = (((max_addr_alloc//4096) + 1)*4096) + 16
		total_alloc_sz = num_alloc_bytes - sum(list(map(lambda x: x[0], mlist)))
		num_new_allocs = num_allocs - len(mlist)
		print("NEED to add missing allocs! ", num_allocs, len(mlist), num_new_allocs, max_addr_alloc, hex(max_addr_alloc), start_addr, fl, total_alloc_sz)
		for i in range( num_new_allocs ):
			if (i == (num_new_allocs - 1)):
				# last alloc:
				mdict, mlist, elist = process_new_alloc(mdict, mlist, elist, (total_alloc_sz), hex(start_addr) )
				print("ADDED LAST alloc: ", mlist[-1])
			else:
				mdict, mlist, elist = process_new_alloc(mdict, mlist, elist, 16, hex(start_addr) )
				total_alloc_sz -= 16
				start_addr += 32
				print("Added new alloc ", mlist[-1], total_alloc_sz, i, start_addr )


	return mdict, mlist, elist

def read_valg_logs(fname, outfile, hist_fname):
	# malloc_dict = {} # addr -> id_in_event_list
	# malloc_list = []
	# # freed_list = [] # addr -> 
	# event_list = [] # either ("m", sz, addr)
	# free_weird_ad = []

	per_process_malloc_dict = {}
	per_process_malloc_list = {}
	per_process_event_list = {}
	per_process_free_weird_ads = {}
	per_process_realloc_weird_ads = {}
	per_process_last_alloc_addr = {}
	per_process_last_alloc_sz = {}

	per_process_max_addr_alloc = {} # max of addr+sz over all allocs.

	# to track allocs active at any given time: 
	per_process_active_allocs = {} # process id -> map: malloc_addr -> size
	per_process_unique_active_allocs = {} # pid -> list of unique active_alloc_maps. we just want 1avg per unique map.
	per_process_avg_active_allocs = {} # pid -> list of avg alloc size [1 element per malloc/free call, since active_avg would vary with each call]

	# NEED to split by process IDs: 
	# Since diff processes could get same virt addr for a malloc, in their own VirtAddr space
	with open(fname) as f:
		ditched_lines = []
		lines19351 = []
		for fl in f.readlines():
			try:
				valid_lines = ["alloc(", "free(", "_Znwm", "_ZdlPv", "memalign(", "_Znam", "ZdaPv("]
				is_valid_fl = sum([ (x in fl) for x in valid_lines ])
				if (is_valid_fl > 0):
					pid = fl.split('--')[1]
					if pid not in per_process_event_list:
						per_process_event_list[pid] = []
						per_process_malloc_dict[pid] = {}
						per_process_malloc_list[pid] = []
						per_process_free_weird_ads[pid] = []
						per_process_realloc_weird_ads[pid] = []
						per_process_active_allocs[pid] = {}
						per_process_avg_active_allocs[pid] = []
						per_process_unique_active_allocs[pid] = set()
						per_process_max_addr_alloc[pid] = 0

					malloc_dict = per_process_malloc_dict[pid]
					malloc_list = per_process_malloc_list[pid]
					event_list = per_process_event_list[pid]
					free_weird_ad = per_process_free_weird_ads[pid]
					realloc_free_weird_ad = per_process_realloc_weird_ads[pid]

					if " malloc(" in fl:
						msz = int(fl.split('(')[1].split(')')[0])
						maddr = fl.split(' ')[3][:-1]
						malloc_dict, malloc_list, event_list = process_new_alloc(malloc_dict, malloc_list, event_list, msz, maddr)	
						per_process_active_allocs[pid] = process_new_active_alloc(per_process_active_allocs[pid], msz, maddr)
						per_process_max_addr_alloc[pid] = max(per_process_max_addr_alloc[pid], int(maddr, base=16) + msz)
						# mid = len(event_list)
						# if (maddr in malloc_dict):
						# 	# Apr17 Update: malloc addresses can be repeated after being free-d!!! [e.g. 2145C040 in mysql]
						# 	if malloc_dict[maddr][2] == 0:
						# 		print("DUPLICATE!!!!! maddr: ", maddr, " already in dict: ", malloc_dict[maddr])
						# 		raise Exception
						# 	else:
						# 		print("RE-USING FREED MEMORY maddr: ", maddr, " alreay in dict: ", malloc_dict[maddr])
						# malloc_dict[ maddr ] = ( msz , mid, 0) # size, id, if its has been freed yet
						# malloc_list.append( (msz, maddr) )
						# event_list.append( (msz, maddr, mid) )
						# print("PID: %s got malloc : %s from line %s"%(pid, str(event_list[-1]), fl[:-1]))
					elif " calloc(" in fl:
						msz = int(fl.split(',')[0].split('(')[1]) * int(fl.split(',')[1].split(')')[0])
						maddr = fl.split(' ')[3][:-1]
						malloc_dict, malloc_list, event_list = process_new_alloc(malloc_dict, malloc_list, event_list, msz, maddr)
						per_process_active_allocs[pid] = process_new_active_alloc(per_process_active_allocs[pid], msz, maddr)
						per_process_max_addr_alloc[pid] = max(per_process_max_addr_alloc[pid], int(maddr, base=16) + msz)
						# mid = len(event_list)
						# malloc_dict[maddr] = (msz, mid, 0)
						# malloc_list.append( (msz, maddr) )
						# event_list.append( (msz, maddr, mid) )
						# print("PID: %s got calloc: %s from line %s"%(pid, str(event_list[-1]), fl[:-1] ))
					elif " realloc(" in fl:
						if "malloc" not in fl: # either only realloc or realloc()free() : need to free in both cases
							# need to free a prev malloc
							realloc_free_ad = fl.split(',')[0].split('(')[1]
							malloc_dict, event_list, realloc_free_weird_ad = process_free_alloc(malloc_dict, event_list, realloc_free_weird_ad, realloc_free_ad)
							per_process_active_allocs[pid] = process_new_active_alloc(per_process_active_allocs[pid], msz, maddr)
							per_process_max_addr_alloc[pid] = max(per_process_max_addr_alloc[pid], int(maddr, base=16) + msz)
							# print("PID: %s Free line: %s, free_addr %s in malloc_dict? %i "%(pid, fl[:-1], realloc_free_ad, (realloc_free_ad in malloc_dict) ))
							# if realloc_free_ad in malloc_dict:
							# 	rm_eid = malloc_dict[realloc_free_ad][1]
							# 	# malloc_dict[realloc_free_ad][2] = 1 # this addr has been free-d
							# 	malloc_dict[realloc_free_ad] = ( malloc_dict[realloc_free_ad][0], rm_eid, 1 )
							# 	print("PID: %s realloc - freeing addr %s [line: %s] , same as malloc_dict: "%(pid, realloc_free_ad, fl[:-1]), malloc_dict[realloc_free_ad])
							# 	event_list.append( (realloc_free_ad, "refree", rm_eid) )
							# else:
							# 	realloc_free_weird_ad.append(realloc_free_ad)
						if "free" not in fl: # either only realloc or realloc()malloc()
							msz = int( fl.split(')')[0].split(',')[1] )
							maddr = fl.split(' ')[3][:-1]
							malloc_dict, malloc_list, event_list = process_new_alloc(malloc_dict, malloc_list, event_list, msz, maddr)
							per_process_active_allocs[pid] = process_free_active_alloc(per_process_active_allocs[pid], maddr)

						# mid = len(event_list)
						# malloc_dict[maddr] = (msz, mid, 0)
						# malloc_list.append( (msz, maddr) )
						# event_list.append( (msz, maddr, mid) )
						# print("PID: %s got realloc %s from line %s"%(pid, str(event_list[-1]), fl[:-1]))
					elif "_Znwm" in fl or "_Znam" in fl:
						# this is a 'new' call.
						msz = int( fl.split(')')[0].split('(')[1] )
						maddr = fl.split(' ')[3][:-1]
						malloc_dict, malloc_list, event_list = process_new_alloc(malloc_dict, malloc_list, event_list, msz, maddr)
						per_process_active_allocs[pid] = process_new_active_alloc(per_process_active_allocs[pid], msz, maddr)
						per_process_max_addr_alloc[pid] = max(per_process_max_addr_alloc[pid], int(maddr, base=16) + msz)
						# print("PID: %s Znwm line: %s, got Znwm!!! event_list[-1]: "%(pid, fl[:-1]), event_list[-1])
					elif "memalign" in fl:
						# TODO!!! unclear why, but the diff b/w memalign returned ptr and the previous alloc's last byte is more than 64by (glibc metadata)
						# Issue: memalign calls return non monotonic addresses! Gap_from_last_alloc is diferent b/w diferent memalign calls!
						msz = int(fl.split(' ')[4][:-1])
						maddr = fl.split(' ')[-1][:-1]
						malloc_dict, malloc_list, event_list = process_new_alloc(malloc_dict, malloc_list, event_list, msz, maddr)
						per_process_active_allocs[pid] = process_new_active_alloc(per_process_active_allocs[pid], msz, maddr)
						per_process_max_addr_alloc[pid] = max(per_process_max_addr_alloc[pid], int(maddr, base=16) + msz)
						# print("PID: %s memalign line: %s, event_list[-1]: "%(pid, fl[:-1]), event_list[-1] )
					elif " malloc_usable_size(" in fl and "realloc(" in fl and "malloc(" in fl:
						msz = int( fl.split(')')[1].split(',')[1] )
						maddr = fl.split(' ')[3][:-1]
						print("PID: %s LINE: %s , msz: %i, maddr: %s, event_list[-1]: "%(pid, fl, msz, maddr), event_list[-1])
						per_process_active_allocs[pid] = process_new_active_alloc(per_process_active_allocs[pid], msz, maddr)
						malloc_dict, malloc_list, event_list = process_new_alloc(malloc_dict, malloc_list, event_list, msz, maddr)
						per_process_max_addr_alloc[pid] = max(per_process_max_addr_alloc[pid], int(maddr, base=16) + msz)
					elif "ZdlPv(" in fl or "ZdaPv(" in fl or "_ZdlPvm(" in fl:
						del_ad = fl.split('(')[1][:-2]
						# print("PID: %s Free line: %s, free_addr %s in malloc_dict? %i "%(pid, fl[:-1], del_ad, (del_ad in malloc_dict) ))
						malloc_dict, event_list, free_weird_ad = process_free_alloc(malloc_dict, event_list, free_weird_ad, del_ad)
						per_process_active_allocs[pid] = process_free_active_alloc(per_process_active_allocs[pid], maddr)
					elif "free(" in fl:
						free_ad = fl.split('(')[1][:-2]
						# print("PID: %s Free line: %s, free_addr %s in malloc_dict? %i "%(pid, fl[:-1], free_ad, (free_ad in malloc_dict) ))
						malloc_dict, event_list, free_weird_ad = process_free_alloc(malloc_dict, event_list, free_weird_ad, free_ad)
						per_process_active_allocs[pid] = process_free_active_alloc(per_process_active_allocs[pid], maddr)
						# if free_ad in malloc_dict:
						# 	m_eid = malloc_dict[free_ad][1]
						# 	malloc_dict[free_ad] = (malloc_dict[free_ad], m_eid, 1)
						# 	print("PID: %s Free line: %s, addr same as malloc_dict: %s"%(pid, fl[:-1], str(event_list[m_eid]) ))
						# 	event_list.append( ( free_ad, "free", m_eid) )
						# else:
						# 	free_weird_ad.append(free_ad)
					else:
						ditched_lines.append(fl)
						if '19351' in fl:
							lines19351.append(fl)
					# Code for active avg STARTS
					# add current avg_active_alloc to arr:
					# For finding avg active alloc size stats: [Not used in final plots: Aug2]
					# if (frozenset(per_process_active_allocs[pid]) not in per_process_unique_active_allocs[pid]):
					# 	per_process_unique_active_allocs[pid].add( frozenset(per_process_active_allocs[pid]) )
					# 	# TODO: count space bw allocs as runs, 
					# 	if (len(per_process_active_allocs[pid]) > 0):
					# 		active_allocs_list = [ (int(x[0], base=16), x[1]) for x in per_process_active_allocs[pid].items() ]
					# 		active_allocs_list = sorted(active_allocs_list, key=lambda x: x[0])
					# 		sizes_list = list(per_process_active_allocs[pid].values())
					# 		for i in range(len(active_allocs_list)):
					# 			if (i == (len(active_allocs_list)-1)):
					# 				# md5sum: total alloc sz is 76080. last run is first_addr+76080 - (alloc[addr]+sz)
					# 				sizes_list.append( (int("0x4A3A040",base=16)+76016) - (active_allocs_list[i-1][0] + active_allocs_list[i-1][1]) )
					# 			elif (i > 0):
					# 				sizes_list.append( active_allocs_list[i][0] - (active_allocs_list[i-1][0] + active_allocs_list[i-1][1]) )
					# 		per_process_avg_active_allocs[pid].append( round(np.mean(sizes_list), 2) )
					# 		if (len(per_process_active_allocs[pid]) < 10):
					# 			print("CURRENT dict: ", per_process_active_allocs[pid], " avg arr: ", per_process_avg_active_allocs[pid])
					# Code for active avg ENDS
				else:
					ditched_lines.append(fl)
					if '19351' in fl:
						lines19351.append(fl)
				# Handling missing allocs:
				if "total heap usage:" in fl:
					pid = (fl.split('==')[1])
					per_process_malloc_dict[pid], per_process_malloc_list[pid], per_process_event_list[pid] = handle_missing_allocs(per_process_malloc_dict[pid], per_process_malloc_list[pid], per_process_event_list[pid], fl, per_process_max_addr_alloc[pid])
			except:
				print("ERROR in line ", fl)
				raise Exception

		# print("DITCHED LINES: ", ditched_lines, " LINES ditched with 19351 ", lines19351)
		
	for pid in list(per_process_event_list.keys()):
		print("FOR process ", pid, " Len(event_list): ", len(per_process_event_list[pid]), " Max Alloc Addr: ", per_process_max_addr_alloc[pid] )
		if ( len(per_process_event_list[pid]) > 0):
			plot_malloc_stats(per_process_malloc_list[pid], "%s_%s.pdf"%(hist_fname, pid) )
			# plot_active_malloc_stats(per_process_avg_active_allocs[pid], "%s_%s_Active.pdf"%(hist_fname, pid) )
			write_valg_workload_to_file(per_process_event_list[pid], "%s_%s.txt"%(outfile, pid))
			print("WEIRD free addr: ", set(per_process_free_weird_ads[pid]), " count: ", len(per_process_free_weird_ads[pid]))
	# print("WEIRD refree addr: ", set(realloc_free_weird_ad), " count: ", len(realloc_free_weird_ad))
# 12bit tag: 44 - 4*0.5 + 4*1.5 => 5712, 
# 16bit => 5950
# plot_arr([4, 8, 12, 16], [0.4239, 0.22157, 0.15414, 0.1204], 'Tag Length (bits)', 'Relative Space Usage (Sb/Sa)', '', 'space_saving_vs_tagSz.pdf')

# argv[1] : name of file containing logs from valgrind --trace-malloc=yes.
# argv[2] : prefix for name of file in which the workload will be saved.
# argv[3] : prefix for name of file in which the histogram of workload will be saved.

valg_logfile = sys.argv[1]
outfile = sys.argv[2]
# debug(valg_logfile)
# read_apache_logs_V1(apache_logfile, outfile, sys.argv[3])
read_valg_logs(valg_logfile, outfile, sys.argv[3])

# apache 19351: Similar for 19350, 19435, 19352 (i.e. 4 child threads)
# 90malloc, 34calloc, 3realloc, 3 malloc_usable_size, 740free.