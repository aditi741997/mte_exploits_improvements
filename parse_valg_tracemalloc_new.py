import os, sys
import math
import matplotlib.font_manager as fm
import matplotlib.pyplot as plt
from matplotlib.ticker import FormatStrFormatter
import numpy as np

params = {'figure.figsize'  : [10, 7.2],
		  # 'font.family': 'MankSans-Medium',
		  'pdf.fonttype' : 42,
          'ps.fonttype' : 42,
		  'grid.color': '#aaaaaa',
		  'grid.linestyle': '--',
		  'grid.linewidth': 1.5,
		  'figure.autolayout': True,
		  } 

fontsz = 23
plt.rcParams.update(params)

# TODO1: Mar21: NEED to add the addr of malloc as well
# Will help decide b/w using new mem or freed mem for the malloc (based on relative offset from first ptr)
# TODO2: in valgrind logs, free can be called multiple times!!! Check for duplicates
# TODO3: in valgrind logs, round up malloc_sz to 16bytes.
# TODO4: first line: put first malloc addr - 64 (i.e. absolute offset)

def write_workload_to_file(imalloc_list, ifreed_allocs_dict, fname):
	s = ""
	for mi in range(len(imalloc_list)):
		s += "malloc %i %i \n"%(mi, imalloc_list[mi][0])
	for free_index in sorted(list(ifreed_allocs_dict.keys())):
		for free_malloc_id in sorted(ifreed_allocs_dict[free_index]):
			s += "free %i \n"%(free_malloc_id)
	with open(fname, 'w') as f:
		f.write(s)

# event_list: each event is either (sz,addr,mid) or (free_addr,free,mid)
def write_valg_workload_to_file(event_list, fname):
	s = ""
	if len(event_list) > 0 and "free" not in event_list[0][1]:
		base_addr = int(event_list[0][1], base=16) - 64
		# s += "%i\n"%(base_addr) # base addr to get offset of all mallocs:
		for ei in range(len(event_list)):
			if "free" not in event_list[ei][1]:
				round_sz = 16*(math.ceil(event_list[ei][0]/16))
				s += "malloc %i %i %i\n"%( round_sz, int(event_list[ei][1], base=16) - base_addr, event_list[ei][2] )
			else:
				s += "free %i %i\n"%( int(event_list[ei][0], base=16) - base_addr, event_list[ei][2])
		with open(fname, 'w') as f:
			f.write(s)
	else:
		print("WEIRD event_list: len: %i, 1st event: %s"%( len(event_list), str(event_list[0]) ))


def plot_malloc_stats(imalloc_list, ifname):
	malloc_sz_list = [ int(16*math.ceil(x[0]/16)) for x in imalloc_list]
	print("[Total #mallocs: %i] Min: %i, median: %i, avg: %i, max: %i", len(malloc_sz_list), min(malloc_sz_list), np.percentile(malloc_sz_list, 50), sum(malloc_sz_list)/len(malloc_sz_list), max(malloc_sz_list))
	print("Counts: 8192: %i , 16: %i"%(malloc_sz_list.count(8192), malloc_sz_list.count(16)))
	plt.yscale("log")
	plt.hist(malloc_sz_list, [16,32,48,64,80,96,160,512,2048,8192,524288,33554980])
	plt.xlabel("Allocation size (bytes)", fontsize=fontsz)
	plt.ylabel("#Allocations", fontsize=fontsz)
	plt.xticks(fontsize=fontsz)
	plt.yticks(fontsize=fontsz)
	plt.locator_params(axis='y')
	plt.savefig(ifname)
	plt.show()


def plot_arr(x_arr, y_arr, xl, yl, titl, ifname):
	# index = np.arange(len(arr)) + 0.3
	# bar_width = 0.4
	# plt.bar(index, )
	plt.plot(x_arr, y_arr, 'bo-')
	plt.xlabel(xl, fontsize=fontsz)
	plt.ylabel(yl, fontsize=fontsz)
	plt.xticks(fontsize=fontsz)
	plt.yticks(fontsize=fontsz)
	plt.savefig(ifname)
	plt.show()

# ONLY account for the apr_palloc, pool_alloc calls, i.e. ignore  the APR CMA metadata (e.g. node/pool/allocator)
# free: find the free with largest addr <= addr for each malloc_addr [for apr_palloc, pool_alloc]
def read_apache_logs_V1(log_fname, out_fname, hist_fname):
	malloc_list = []  # stores tuples of (malloc sz, ptr)
	freed_dict = {} # stores ptr->free'd index.
	with open(log_fname) as f:
		for fl in f.readlines():
			try:
				if "APR_PALLOC: Actual alloc size:" in fl:
					addr = int(fl.split(' ')[8],base=16)
					if addr < 79499320:
						print("###### WEIRD malloc addr: ", fl)
					else:
						malloc_list.append( ( int(fl.split(' ')[4] ), addr ) )
				elif "POOL_ALLOC: CALLED malloc for mem" in fl:
					addr = int(fl.split(' ')[8],base=16)
					if addr < 79499320:
						print("###### WEIRD malloc addr: ", fl)
					else:
						malloc_list.append( (int(fl.split(' ')[6]), int(fl.split(' ')[8],base=16)) )
				elif "Calling free on" in fl:
					freed_ptr = int( fl.split(' ')[4] , base=16)
					freed_dict[freed_ptr] = len(freed_dict)
			except:
				print("###### ERROR in Line ", fl)
				# raise
	freed_allocs_dict = {} # stores free'd index->list of malloc' items that it frees
	freed_addr_list = sorted(list(freed_dict.keys()))
	for i in range(len(malloc_list)):
		malloc_item = malloc_list[i]

		# find the free that frees this malloc_item:
		try:
			freed_addr = max( [fa for fa in freed_addr_list if (fa <= malloc_item[1])] )
			freed_index = freed_dict[freed_addr]

			# add this to freed_allocs_dict:
			if freed_index not in freed_allocs_dict:
				freed_allocs_dict[freed_index] = []
			freed_allocs_dict[freed_index].append(i)
		except:
			print("ERROR for malloc item", malloc_item, "index: ", i, "freed_addr_list: ", freed_addr_list)
			raise
	plot_malloc_stats(malloc_list, hist_fname)
	write_workload_to_file(malloc_list, freed_allocs_dict, out_fname)


# Account for node [40bytes in allocator_alloc]/pool [sizeof_pool in ?]/allocator [?] metadata
# Along with apr_palloc, pool_alloc calls
# free: find the free with largest addr <= addr for each malloc_addr [for apr_palloc, pool_alloc]
def read_apache_logs_V2(fname, out_fname, hist_fname):
	malloc_list = []
	freed_dict = {}
	counts = {"APR_PALLOC: Actual alloc size": 0, "POOL_ALLOC: CALLED malloc for mem": 0, "pool metadata space": 0, "node first_avail is": 0, "make new_allocator": 0}
	with open(fname) as f:
		for fl in f.readlines():
			try:
				if "APR_PALLOC: Actual alloc size:" in fl:
					addr = int(fl.split(' ')[8],base=16)
					if addr < 79499320:
						print("###### WEIRD malloc addr: ", fl)
					else:
						malloc_list.append( ( int(fl.split(' ')[4] ), addr ) )
						counts["APR_PALLOC: Actual alloc size"] += 1
				elif "POOL_ALLOC: CALLED malloc for mem" in fl:
					addr = int(fl.split(' ')[8],base=16)
					if addr < 79499320:
						print("###### WEIRD malloc addr: ", fl)
					else:
						malloc_list.append( (int(fl.split(' ')[6]), int(fl.split(' ')[8],base=16)) )
						counts["POOL_ALLOC: CALLED malloc for mem"] += 1
				# apr metadata:
				elif "pool metadata space" in fl:
					malloc_list.append( ( int(fl.split(' ')[9]), 0 ) )
					counts["pool metadata space"] += 1
				elif "node first_avail is" in fl:
					malloc_list.append( (int(fl.split(' ')[4]), 0) )
					counts["node first_avail is"] += 1
				elif "make new_allocator" in fl:
					malloc_list.append( (int(fl.split(' ')[8]), 0) )
					counts["make new_allocator"] += 1
				elif "Calling free on" in fl:
					freed_ptr = int( fl.split(' ')[4] , base=16)
					freed_dict[freed_ptr] = len(freed_dict)
			except:
				print("###### ERROR in Line ", fl)
	print(counts)
	plot_malloc_stats(malloc_list, hist_fname)
	#Todo: convert malloc list, free list to workload. Main Issue: Order

def process_new_alloc(mdict, mlist, elist, msz, maddr):
	mid = len(elist)
	if (maddr in mdict):
		if mdict[maddr][2] == 0:
			print("DUPLICATE!!!!! maddr: ", maddr, " already in dict: ", mdict[maddr])
			raise Exception
		# else:
			# print("RE-USING FREED MEMORY maddr: ", maddr, " alreay in dict: ", mdict[maddr])
	mdict[ maddr ] = ( msz , mid, 0) # size, id, if its has been freed yet
	mlist.append( (msz, maddr) )
	elist.append( (msz, maddr, mid) )
	return (mdict, mlist, elist)

def process_free_alloc(mdict, elist, f_weird_list, free_addr):
	if free_addr in mdict:
		m_eid = mdict[free_addr][1]
		mdict[free_addr] = (mdict[free_addr][0], m_eid, 1)
		elist.append( ( free_addr, "free", m_eid) )
	else:
		f_weird_list.append(free_addr)
	return (mdict, elist, f_weird_list)

def debug(fname):
	with open(fname) as f:
		all19351 = []
		valid19351 = []
		invalid19351 = []
		parsed19351 = []
		mrc19351 = []
		nonmrc19351 = []
		ditched19351 = []
		for fl in f.readlines():
			if "19351" in fl:
				all19351.append(fl)
				valid_lines = ["alloc(", "free(", "_Znwm", "_ZdlPv", "memalign(", "_Znam", "ZdaPv("]
				is_valid_fl = sum([ (x in fl) for x in valid_lines ])
				if is_valid_fl > 0:
					valid19351.append(fl)
					if " malloc(" in fl or " calloc(" in fl or " realloc(" in fl:
						mrc19351.append(fl)
					elif "free(" not in fl:
						nonmrc19351.append(fl)

					if " malloc(" in fl or " calloc(" in fl or " realloc(" in fl or "memalign" in fl or "free(" in fl:
						parsed19351.append(fl)					
					else:
						ditched19351.append(fl)
				else:
					invalid19351.append(fl)
		print("LENs: all: %i, valid: %i, invalid: %i, parsed: %i, ditched: %i"%(len(all19351), len(valid19351), len(invalid19351), len(parsed19351), len(ditched19351)))
		print(invalid19351)
		print("mrc: %i, nonmrc: %i "%(len(mrc19351), len(nonmrc19351)))

def read_valg_logs(fname, outfile, hist_fname):
	# malloc_dict = {} # addr -> id_in_event_list
	# malloc_list = []
	# # freed_list = [] # addr -> 
	# event_list = [] # either ("m", sz, addr)
	# free_weird_ad = []

	per_process_malloc_dict = {}
	per_process_malloc_list = {}
	per_process_event_list = {}
	per_process_free_weird_ads = {}
	per_process_realloc_weird_ads = {}
	per_process_last_alloc_addr = {}
	per_process_last_alloc_sz = {}
	# NEED to split by process IDs: 
	# Since diff processes could get same virt addr for a malloc, in their own VirtAddr space
	with open(fname) as f:
		ditched_lines = []
		lines19351 = []
		for fl in f.readlines():
			try:
				valid_lines = ["alloc(", "free(", "_Znwm", "_ZdlPv", "memalign(", "_Znam", "ZdaPv("]
				is_valid_fl = sum([ (x in fl) for x in valid_lines ])
				if (is_valid_fl > 0):
					pid = fl.split('--')[1]
					if pid not in per_process_event_list:
						per_process_event_list[pid] = []
						per_process_malloc_dict[pid] = {}
						per_process_malloc_list[pid] = []
						per_process_free_weird_ads[pid] = []
						per_process_realloc_weird_ads[pid] = []

					malloc_dict = per_process_malloc_dict[pid]
					malloc_list = per_process_malloc_list[pid]
					event_list = per_process_event_list[pid]
					free_weird_ad = per_process_free_weird_ads[pid]
					realloc_free_weird_ad = per_process_realloc_weird_ads[pid]

					if " malloc(" in fl:
						msz = int(fl.split('(')[1].split(')')[0])
						maddr = fl.split(' ')[3][:-1]
						malloc_dict, malloc_list, event_list = process_new_alloc(malloc_dict, malloc_list, event_list, msz, maddr)	
						# mid = len(event_list)
						# if (maddr in malloc_dict):
						# 	# Apr17 Update: malloc addresses can be repeated after being free-d!!! [e.g. 2145C040 in mysql]
						# 	if malloc_dict[maddr][2] == 0:
						# 		print("DUPLICATE!!!!! maddr: ", maddr, " already in dict: ", malloc_dict[maddr])
						# 		raise Exception
						# 	else:
						# 		print("RE-USING FREED MEMORY maddr: ", maddr, " alreay in dict: ", malloc_dict[maddr])
						# malloc_dict[ maddr ] = ( msz , mid, 0) # size, id, if its has been freed yet
						# malloc_list.append( (msz, maddr) )
						# event_list.append( (msz, maddr, mid) )
						# print("PID: %s got malloc : %s from line %s"%(pid, str(event_list[-1]), fl[:-1]))
					elif " calloc(" in fl:
						msz = int(fl.split(',')[0].split('(')[1]) * int(fl.split(',')[1].split(')')[0])
						maddr = fl.split(' ')[3][:-1]
						malloc_dict, malloc_list, event_list = process_new_alloc(malloc_dict, malloc_list, event_list, msz, maddr)
						# mid = len(event_list)
						# malloc_dict[maddr] = (msz, mid, 0)
						# malloc_list.append( (msz, maddr) )
						# event_list.append( (msz, maddr, mid) )
						# print("PID: %s got calloc: %s from line %s"%(pid, str(event_list[-1]), fl[:-1] ))
					elif " realloc(" in fl:
						if "malloc" not in fl:
							# need to delete a prev malloc
							realloc_free_ad = fl.split(',')[0].split('(')[1]
							malloc_dict, event_list, realloc_free_weird_ad = process_free_alloc(malloc_dict, event_list, realloc_free_weird_ad, realloc_free_ad)
							# print("PID: %s Free line: %s, free_addr %s in malloc_dict? %i "%(pid, fl[:-1], realloc_free_ad, (realloc_free_ad in malloc_dict) ))
							# if realloc_free_ad in malloc_dict:
							# 	rm_eid = malloc_dict[realloc_free_ad][1]
							# 	# malloc_dict[realloc_free_ad][2] = 1 # this addr has been free-d
							# 	malloc_dict[realloc_free_ad] = ( malloc_dict[realloc_free_ad][0], rm_eid, 1 )
							# 	print("PID: %s realloc - freeing addr %s [line: %s] , same as malloc_dict: "%(pid, realloc_free_ad, fl[:-1]), malloc_dict[realloc_free_ad])
							# 	event_list.append( (realloc_free_ad, "refree", rm_eid) )
							# else:
							# 	realloc_free_weird_ad.append(realloc_free_ad)
						msz = int( fl.split(')')[0].split(',')[1] )
						maddr = fl.split(' ')[3][:-1]
						malloc_dict, malloc_list, event_list = process_new_alloc(malloc_dict, malloc_list, event_list, msz, maddr)
						# mid = len(event_list)
						# malloc_dict[maddr] = (msz, mid, 0)
						# malloc_list.append( (msz, maddr) )
						# event_list.append( (msz, maddr, mid) )
						# print("PID: %s got realloc %s from line %s"%(pid, str(event_list[-1]), fl[:-1]))
					elif "_Znwm" in fl or "_Znam" in fl:
						# this is a 'new' call.
						msz = int( fl.split(')')[0].split('(')[1] )
						maddr = fl.split(' ')[3][:-1]
						malloc_dict, malloc_list, event_list = process_new_alloc(malloc_dict, malloc_list, event_list, msz, maddr)
						# print("PID: %s Znwm line: %s, got Znwm!!! event_list[-1]: "%(pid, fl[:-1]), event_list[-1])
					elif "memalign" in fl:
						# TODO!!! unclear why, but the diff b/w memalign returned ptr and the previous alloc's last byte is more than 64by (glibc metadata)
						# Issue: memalign calls return non monotonic addresses! Gap_from_last_alloc is diferent b/w diferent memalign calls!
						msz = int(fl.split(' ')[4][:-1])
						maddr = fl.split(' ')[-1][:-1]
						malloc_dict, malloc_list, event_list = process_new_alloc(malloc_dict, malloc_list, event_list, msz, maddr)
						# print("PID: %s memalign line: %s, event_list[-1]: "%(pid, fl[:-1]), event_list[-1] )
					elif "ZdlPv(" in fl or "ZdaPv(" in fl:
						del_ad = fl.split('(')[1][:-2]
						# print("PID: %s Free line: %s, free_addr %s in malloc_dict? %i "%(pid, fl[:-1], del_ad, (del_ad in malloc_dict) ))
						malloc_dict, event_list, free_weird_ad = process_free_alloc(malloc_dict, event_list, free_weird_ad, del_ad)
					elif "free(" in fl:
						free_ad = fl.split('(')[1][:-2]
						# print("PID: %s Free line: %s, free_addr %s in malloc_dict? %i "%(pid, fl[:-1], free_ad, (free_ad in malloc_dict) ))
						malloc_dict, event_list, free_weird_ad = process_free_alloc(malloc_dict, event_list, free_weird_ad, free_ad)
						# if free_ad in malloc_dict:
						# 	m_eid = malloc_dict[free_ad][1]
						# 	malloc_dict[free_ad] = (malloc_dict[free_ad], m_eid, 1)
						# 	print("PID: %s Free line: %s, addr same as malloc_dict: %s"%(pid, fl[:-1], str(event_list[m_eid]) ))
						# 	event_list.append( ( free_ad, "free", m_eid) )
						# else:
						# 	free_weird_ad.append(free_ad)
					else:
						ditched_lines.append(fl)
						if '19351' in fl:
							lines19351.append(fl)
				else:
					ditched_lines.append(fl)
					if '19351' in fl:
						lines19351.append(fl)
			except:
				print("ERROR in line ", fl)
				raise Exception
		print("DITCHED LINES: ", ditched_lines, " LINES ditched with 19351 ", lines19351)
	for pid in list(per_process_event_list.keys()):
		print("FOR process ", pid, " Len(event_list): ", len(per_process_event_list[pid]) )
		if ( len(per_process_event_list[pid]) > 0):
			plot_malloc_stats(per_process_malloc_list[pid], "%s_%s.pdf"%(hist_fname, pid) )
			write_valg_workload_to_file(per_process_event_list[pid], "%s_%s.txt"%(outfile, pid))
			print("WEIRD free addr: ", set(per_process_free_weird_ads[pid]), " count: ", len(per_process_free_weird_ads[pid]))
	# print("WEIRD refree addr: ", set(realloc_free_weird_ad), " count: ", len(realloc_free_weird_ad))
# 12bit tag: 44 - 4*0.5 + 4*1.5 => 5712, 
# 16bit => 5950
# plot_arr([4, 8, 12, 16], [0.4239, 0.22157, 0.15414, 0.1204], 'Tag Length (bits)', 'Relative Space Usage (Sb/Sa)', '', 'space_saving_vs_tagSz.pdf')

# argv[1] : name of file containing logs from valgrind --trace-malloc=yes.
# argv[2] : prefix for name of file in which the workload will be saved.
# argv[3] : prefix for name of file in which the histogram of workload will be saved.

valg_logfile = sys.argv[1]
outfile = sys.argv[2]
# debug(valg_logfile)
# read_apache_logs_V1(apache_logfile, outfile, sys.argv[3])
read_valg_logs(valg_logfile, outfile, sys.argv[3])

# apache 19351: Similar for 19350, 19435, 19352 (i.e. 4 child threads)
# 90malloc, 34calloc, 3realloc, 3 malloc_usable_size, 740free.