import os, sys
import seaborn as sns
import math
import matplotlib.font_manager as fm
import matplotlib.pyplot as plt
from matplotlib.ticker import FormatStrFormatter
import numpy as np
from matplotlib import ticker
import pandas as pd
from io import StringIO

params = {'figure.figsize'  : [10, 7.2],
          # 'font.family': 'MankSans-Medium',
          'pdf.fonttype' : 42,
          'ps.fonttype' : 42,
          'grid.color': '#aaaaaa',
          'grid.linestyle': '--',
          'grid.linewidth': 1.0,
          'figure.autolayout': True,
          } 

font_size = 18
legend_font_size = 16
plt.rcParams.update(params)

plt.rc('font', size=font_size)        # controls default text sizes
plt.rc('axes', titlesize=font_size)   # fontsize of the axes title
plt.rc('axes', labelsize=font_size)   # fontsize of the x and y labels
plt.rc('xtick', labelsize=font_size-2)  # fontsize of the tick labels
plt.rc('ytick', labelsize=font_size-2)  # fontsize of the tick labels
plt.rc('legend', fontsize=legend_font_size)  # legend fontsize

bar_width = 1

output_fmt = 'pdf'

# Color mapping (for consistent colors)
all_colors = sns.color_palette('PuBu', 8)

def get_workload_results(fname):
    with open(fname, 'r') as sf:
        all_lines = sf.readlines()
        sfl = all_lines[1:-2]

        #  could do this if sfl was one giant string:
        # df = pd.read_csv(StringIO(str(sfl)), sep=", ")
        columns = [x.replace(' ', '').replace('\n','') for x in (all_lines[0].split(', '))]
        print(columns, len(columns))
        df = pd.DataFrame([row.split(', ')[:-1] for row in sfl], columns=columns )
        for col in df.columns:
            df[col] = pd.to_numeric(df[col])
        print(df.columns, df.head(), df.count(), df.dtypes)

        df = df[ df["PageTouched"] > 0 ]
        print("Touched: Count: ", df.count())

        print("Avg #allocs per pg: ", df["NumAllocs"].mean())
        # df["Pg_StgAvg"] = df["Pg_StgSum"]/df["Pg_StgCount"]
        # df["Pg_LdgAvg"] = df["Pg_LdgSum"]/df["Pg_LdgCount"]
        
        # FOR debug:
        print(df["NumAllocs"].describe())

        print("Avg stg time: ", df["Pg_StgSum"].sum()/df["Pg_StgCount"].sum())
        print("Avg Ldg time: ", df["Pg_LdgSum"].sum()/df["Pg_LdgCount"].sum())
        print("Max stg times: ", df["Pg_StgMax"].mean(), df["Pg_StgMax"].max())
        print("Max Ldg times: ", df["Pg_LdgMax"].mean(), df["Pg_LdgMax"].max())
        print("Depth: ", df["Page_OurBTreeDepth"].describe() )

        try:
            print("Avg stg ARR time: ", df["Pg_StgArrSum"].sum()/df["Pg_StgArrCount"].sum())
            print("Avg Ldg ARR time: ", df["Pg_LdgArrSum"].sum()/df["Pg_LdgArrCount"].sum())
        except:
            print("COULD NOT FIND Pg_StgArrSum/Pg_LdgArrSum in ", fname)

        try:
            avg_max_runs = float(df["Page_MaxNumRuns"].sum()/df.shape[0])
            print("Avg MaxNumRuns per page: ", avg_max_runs )
        except:
            avg_max_runs = 0
            print("COULD NOT FIND Page_MaxNumRuns in ", fname)

        ct_pages_touched = 0

        num_allocs_per_page = []
        sum_allocs_per_page = []
        avg_alloc_sz_per_page = []
        num_pgs_with_one_alloc = 0

        ct_pages_with_tagArr = 0
        total_mem_tagArr = 0
        total_mem_btree = 0

        # # stg, ldg perf measure:
        # stg_stats_per_page = {'ct': [], 'avg': [], 'min': [], 'max': []}
        # ldg_stats_per_page = {'ct': [], 'avg': [], 'min': [], 'max': []}

        # # tree depth:
        # tree_depth_per_page = []

        for l in sfl:
            lsp = l.split(', ')
            if (int(lsp[1]) == 1): # PageTouched
                ct_pages_touched += 1
                num_allocs_per_page.append(int(lsp[2]))
                sum_allocs_per_page.append(int(lsp[3])*16) # Allocated mem In Bytes
                avg_alloc_sz_per_page.append(sum_allocs_per_page[-1]/float(num_allocs_per_page[-1]))

                total_mem_tagArr += 128
                total_mem_btree += int(lsp[-2])

                if (int(lsp[-2]) == 128):
                    ct_pages_with_tagArr += 1

                if (int(lsp[2]) == 1):
                    num_pgs_with_one_alloc += 1

        num_allocs_per_page = np.array(num_allocs_per_page)
        sum_allocs_per_page = np.array(sum_allocs_per_page)

        # Allocation STATS:
        print("MEAN #Allocs per page: %f, Median: %f"%(np.mean(num_allocs_per_page), np.percentile(num_allocs_per_page, 50)), " MEAN,Med,Min,Max Avg Alloc Size per page: ", np.mean(avg_alloc_sz_per_page), np.median(avg_alloc_sz_per_page), min(avg_alloc_sz_per_page), max(avg_alloc_sz_per_page) )

        # BTree STATS:
        print("#Pages touched: ", ct_pages_touched, "#Pgs with 1 alloc: %i, TagArr: %i, BTree: %i TOTAL Mem savings: %f, #Pgs with TagArr: %i"%(num_pgs_with_one_alloc, total_mem_tagArr, total_mem_btree, total_mem_tagArr/float(total_mem_btree), ct_pages_with_tagArr ) )

        # sf.readlines()[-2] : tagArray space usage wrt time
        tagArr_space_per_event = [int(x) for x in all_lines[-2].split(', ')[:-1]]
        # sf.readlines()[-1] : btree space usage wrt time
        btree_space_per_event = [int(x) for x in all_lines[-1].split(', ')[:-1]]

        return num_allocs_per_page, sum_allocs_per_page, avg_alloc_sz_per_page, num_pgs_with_one_alloc, ct_pages_with_tagArr, total_mem_btree, total_mem_tagArr, max(btree_space_per_event), df["Page_OurSpaceUsage"].sum(), avg_max_runs


workloads = ['apache2', 'ffmpeg', 'md5', 'pbzip2'] #, 'axel', 'ffmpeg', 
workload_ids = { workloads[i]:i for i in range(len(workloads))}

# Plot:
# y-axis: proportion of pgs using 4-bit tag arr
# x-axis: 5 workloads, 4bars for each: TagArr, 4bitBT, 8bitBT, 16bitBT

def plot_grouped_bars(workloads, d, group_order, ylabel, fname, percetage, ncol, ybox):
    xtick_names = workloads # group names
    num_bar_groups = len(group_order) # #bars on each xtixk

    fig, ax1 = plt.subplots(figsize=(7, 3), ncols=1, nrows=1, sharex=True, sharey=False)
    fig.tight_layout()

    # assuming bar width = 1
    for gi in range(num_bar_groups):
        all_x = (np.arange(len(workloads)))*(num_bar_groups+2) + gi
        ax1.bar(all_x, d[group_order[gi]], width=1, color=color_map[group_order[gi]], label=group_order[gi])

    ax1.set_xticks( (np.arange(len(workloads)))*(num_bar_groups+2) + num_bar_groups/2 - bar_width/2 ) # commenting only for running locally
    ax1.set_xticklabels(workloads)
    ax1.set_ylabel(ylabel)
    ax1.set_ylim(bottom=0,top=(105 if percetage else 1.05))

    ax1.set_axisbelow(True) # to put the gridlines behind bars
    ax1.yaxis.grid()

    y1_ticks = ticker.MaxNLocator(5)
    ax1.yaxis.set_major_locator(y1_ticks)

    fig.legend(loc='upper center', bbox_to_anchor=(0.5, ybox), ncol=ncol)

    plt.savefig("%s_%iWorkloads.%s"%(fname, len(workloads), output_fmt ), format=output_fmt, bbox_inches='tight', pad_inches=0.1 )

workloads_page_prop_tag_arr = {'Tag Array': [0 for x in workloads], '4-bit BTree': [0 for x in workloads], '8-bit BTree': [0 for x in workloads], '16-bit BTree': [0 for x in workloads], '32-bit BTree': [0 for x in workloads]}

# max of btree_total space usage, over time
workloads_relative_MS_space_usage_arr = {'Tag Array': [1 for x in workloads], '4-bit BTree': [1 for x in workloads], '8-bit BTree': [1 for x in workloads], '16-bit BTree': [1 for x in workloads], '32-bit BTree': [1 for x in workloads]}
# sum of max space usage for each page
workloads_relative_SM_space_usage_arr = {'Tag Array': [1 for x in workloads], '4-bit BTree': [1 for x in workloads], '8-bit BTree': [1 for x in workloads], '16-bit BTree': [1 for x in workloads], '32-bit BTree': [1 for x in workloads]}

color_map = {'Tag Array': all_colors[3], '4-bit BTree': all_colors[4], '8-bit BTree': all_colors[5], '16-bit BTree': all_colors[6], '32-bit BTree': all_colors[7]}

# get_workload_results("aarch64_workloads_AWS/btree_results/Old Results/axel_llvm_readme_1714_PerPageBTreeStats_4b_FBitArr_Opt.csv")

workloads_avg_max_runs = {x:0 for x in workloads}

for workload in workloads:
    for taglen in [4, 8, 16, 32]:
    # for taglen in [4, 8, 16]:
        for f in os.listdir(os.path.join(sys.argv[1], "%sbit_Results"%(taglen)) ):
            print(f)
            check_for_newdebug = True if (taglen == 4 or taglen == 32) else ("ND_Final" in f)
            if workload in f and "Final_%ibit"%(taglen) in f and ".csv" in f and check_for_newdebug:
                print("FOUND file ", f, " for ", workload, taglen)
                na, sa, avg, n1, ct_tag, btree, arr, btree_space_max_sum, btree_space_sum_max, w_avg_max_runs = get_workload_results( os.path.join(sys.argv[1], "%sbit_Results"%(taglen), f) )
                workloads_page_prop_tag_arr['%i-bit BTree'%(taglen)][ workload_ids[workload] ] = 100*(1 - float(ct_tag)/len(na))
                workloads_relative_MS_space_usage_arr['%i-bit BTree'%(taglen)][ workload_ids[workload] ] = btree_space_max_sum/float(arr)
                workloads_relative_SM_space_usage_arr['%i-bit BTree'%(taglen)][ workload_ids[workload] ] = btree_space_sum_max/float(arr)
                
                print("For ", workload, taglen, len(na), n1, ct_tag, btree, arr, " Metric: ", float(ct_tag)/len(na), workloads_page_prop_tag_arr)
                workloads_avg_max_runs[workload] = max(workloads_avg_max_runs[workload], w_avg_max_runs)

print("MORE REALISTIC metric: max of (btree_total space usage over time): ", workloads_relative_MS_space_usage_arr)
print("PESSIMISTIC metric: sum of (max space usage for each Page over time)", workloads_relative_SM_space_usage_arr)

plot_grouped_bars(workloads, workloads_page_prop_tag_arr, ['4-bit BTree', '8-bit BTree', '16-bit BTree', '32-bit BTree'], "%Pages using BTree", "Prop_Pages_Using_Btree_New", 1, 2, 1.2) # use ncol=2,ybox=1.2 for 4-32bit results. and ncol=3,ybox=1.1 for 4-16bit results plot
plot_grouped_bars(workloads, workloads_relative_MS_space_usage_arr, ['Tag Array', '4-bit BTree', '8-bit BTree', '16-bit BTree', '32-bit BTree'], "Relative Space Usage", "SpaceUsage_BTree_Relative_4bTagArr_New", 0, 3, 1.2)

# Added avg max#runs in table.
# from plot_workload_stats import plot_bar

# print("AVG Max#Runs per pge: ", workloads_avg_max_runs)
# plot_bar([workloads_avg_max_runs[w] for w in workloads], workloads, None, os.path.join(sys.argv[2], "All5Workloads_Avg_MaxRuns"))
